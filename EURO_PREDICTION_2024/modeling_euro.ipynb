{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false
   },
   "source": "import snowflake.snowpark\nfrom snowflake.snowpark.session import Session\nfrom snowflake.snowpark import Window\nfrom snowflake.snowpark import functions as F   \nfrom snowflake.snowpark.functions import udf, udtf\nfrom snowflake.snowpark.types import IntegerType, FloatType, StringType, StructField, StructType, DateType\n    \nimport pandas as pd\nimport numpy as np\nimport streamlit as st\n\nimport warnings\nwarnings.filterwarnings('ignore')\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "collapsed": false
   },
   "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# add version tracking\napp_tag = {\n    \"origin\": \"sf_sit\",\n    \"name\": \"hol_sport_predict\",\n    \"version\": '{major: 1, minor: 0}'\n}\n\nsession.query_tag = app_tag",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "collapsed": false
   },
   "source": "user_name = session.sql('select current_user()').collect()[0][0]\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "3a193a58-1131-4040-a38b-db0123be0606",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "collapsed": false
   },
   "outputs": [],
   "source": "# FUNCTION used to iterate the model version so we can automatically create the next version number\n\nimport ast\n\ndef get_next_version(reg, model_name) -> str:\n    \"\"\"\n    Returns the next version of a model based on the existing versions in the registry.\n\n    Args:\n        reg: The registry object that provides access to the models.\n        model_name: The name of the model.\n\n    Returns:\n        str: The next version of the model in the format \"V_\".\n\n    Raises:\n        ValueError: If the version list for the model is empty or if the version format is invalid.\n    \"\"\"\n    models = reg.show_models()\n    if models.empty:\n        return \"V_1\"\n    elif model_name not in models[\"name\"].to_list():\n        return \"V_1\"\n    max_version_number = max(\n        [\n            int(version.split(\"_\")[-1])\n            for version in ast.literal_eval(\n                models.loc[models[\"name\"] == model_name, \"versions\"].values[0]\n            )\n        ]\n    )\n    return f\"V_{max_version_number + 1}\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7dd56921-6c6c-4068-8fe1-d262498c8574",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "collapsed": false
   },
   "outputs": [],
   "source": "# check distribution to see how balanced out data set is\n# we will also filter out rows where the rank difference is 0, shouldnt be any...\n\ndf_training = session.table(f'final_data_{user_name}')\n\n# ignore games where there's no rank difference\ndf_training = df_training.filter( \n    (F.col('team_1_vs_team_2_rank') != 0) & \n    (F.col('team_1_vs_team_2_rank').is_not_null())\n) \n\ndf_data_dist = df_training.group_by('game_outcome').agg(F.count('ID')).sort(F.col('game_outcome'))\n\nst.dataframe(data=df_data_dist)\nst.bar_chart(df_data_dist,x='GAME_OUTCOME')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fff45f79-3041-4bcf-98fe-e55dfd4ca0c3",
   "metadata": {
    "language": "sql",
    "name": "cell6",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- we want to do some hyperparameter tuning, in order to speed things up lets size up our warehouse\n-- note - this is just temporary for HPO\n\nalter warehouse euro2024_wh set warehouse_size = xlarge",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "78c03b62-baf4-46a0-bfed-91f7675e48b7",
   "metadata": {
    "language": "sql",
    "name": "cell7",
    "collapsed": false
   },
   "outputs": [],
   "source": "\n-- let's check we now have the new size\n\nshow warehouses like 'EURO2024_WH'\n     ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ba90653f-0cfe-43d0-8b26-7101cf07080a",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "collapsed": false
   },
   "outputs": [],
   "source": "# and now lets run Hyper Parameter tuning to get the best parameters\n# hyper parameter grid is 6x6x6, with 5 folds thats 1,080 versions!\n\nfrom snowflake.ml.modeling.preprocessing import StandardScaler\nfrom snowflake.ml.modeling.pipeline import Pipeline\nfrom snowflake.ml.modeling.xgboost import XGBClassifier\nfrom snowflake.ml.modeling.model_selection.grid_search_cv import GridSearchCV\n\ntrain_data = df_training\n\nFEATURE_COLS = [c for c in train_data.columns if c != \"GAME_OUTCOME\" and c != \"ID\"]\nLABEL_COLS = [\"GAME_OUTCOME\"]\n\nhyperparam_grid = {\n    \"n_estimators\": [50, 100, 200, 300, 400, 500],\n    \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3, 0.4],\n    \"max_depth\": [3, 4, 5, 6, 7, 8]\n}\n\npipeline = Pipeline(\n    steps = [\n        (\n            \"scaler\", \n            StandardScaler(\n                input_cols=FEATURE_COLS, \n                output_cols=FEATURE_COLS\n            )\n        ),\n        (\n        \"GridSearchCV\",\n            GridSearchCV(\n                estimator=XGBClassifier(random_state=42),\n                param_grid=hyperparam_grid,\n                scoring='accuracy', \n                label_cols=LABEL_COLS,\n                input_cols=FEATURE_COLS\n            )   \n        )\n    ]\n)\n\npipeline.fit(train_data)\n\nsklearn_hp = pipeline.to_sklearn()\noptimal_params = sklearn_hp.steps[-1][1].best_params_\nscore_dict = {\"best_accuracy\": sklearn_hp.steps[-1][1].best_score_}\n\nst.write(score_dict)\nst.write(optimal_params)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "15108542-bba1-445f-977a-8ede3286de4f",
   "metadata": {
    "language": "sql",
    "name": "cell9"
   },
   "outputs": [],
   "source": "-- now we can scale it back down, it a matter of seconds\n\nalter warehouse euro2024_wh set warehouse_size = xsmall",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0adb0bcd-4892-4142-8c6d-45f7d5b33a10",
   "metadata": {
    "language": "sql",
    "name": "cell10"
   },
   "outputs": [],
   "source": "-- let's check we're back down to a XS\nshow warehouses like 'EURO2024_WH'",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "67becce2-1929-4979-9311-a6a60c0378b5",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": "# taking our optimal parameters we're going to build our model\n\nfrom snowflake.ml.modeling.preprocessing import StandardScaler\nfrom snowflake.ml.modeling.pipeline import Pipeline\nfrom snowflake.ml.modeling.xgboost import XGBClassifier\nfrom snowflake.ml.modeling.metrics import *\n\ntrain_data, test_data = df_training.random_split(weights=[0.8, 0.2], seed=0)\n\nFEATURE_COLS = [c for c in train_data.columns if c != \"GAME_OUTCOME\" and c != \"ID\"]\nLABEL_COLS = [\"GAME_OUTCOME\"]\n\npipeline = Pipeline(\n    steps = [\n        (\n            \"scaler\", \n            StandardScaler(\n                input_cols=FEATURE_COLS, \n                output_cols=FEATURE_COLS\n            )\n        ),\n        (\n            \"model\", \n            XGBClassifier(\n                input_cols=FEATURE_COLS, \n                label_cols=LABEL_COLS,\n                max_depth=optimal_params['max_depth'],\n                n_estimators = optimal_params['n_estimators'],\n                learning_rate = optimal_params['learning_rate']\n            )\n        )\n    ]\n)\n\npipeline.fit(train_data)\n\n# get the model accuracy\npredict_on_training_data = pipeline.predict(train_data)\ntraining_accuracy = accuracy_score(df=predict_on_training_data, y_true_col_names=[\"GAME_OUTCOME\"], y_pred_col_names=[\"OUTPUT_GAME_OUTCOME\"])\npredict_on_test_data = pipeline.predict(test_data)\neval_accuracy = accuracy_score(df=predict_on_test_data, y_true_col_names=[\"GAME_OUTCOME\"], y_pred_col_names=[\"OUTPUT_GAME_OUTCOME\"])\n\nst.write(f\"Training accuracy: {training_accuracy} \\nEval accuracy: {eval_accuracy}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fe0f6d24-c754-4e7e-995c-d1564f7aed98",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "from snowflake.ml.registry import Registry\n\nreg = Registry(session=session)\n\nmodel_name = \"EURO_24_GAME_PREDICT\"\nmodel_version = get_next_version(reg, model_name)\n\nreg.log_model(\n    model_name=model_name,\n    version_name=model_version,\n    model=pipeline,\n    metrics={\n        'training_accuracy':training_accuracy, \n        'eval_accuracy':eval_accuracy\n    },\n    options={\n        'relax_version': False,\n        'embed_local_ml_library': True       \n    }\n)\n\nm = reg.get_model(model_name)\nm.default = model_version",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eca71aae-877b-49cc-95e7-0b712af164aa",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": "# lets see the models we have in our registry\n\nreg.get_model(model_name).show_versions()",
   "execution_count": null
  }
 ]
}